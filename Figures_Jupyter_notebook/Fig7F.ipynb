{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2694d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:00:39.165630Z",
     "start_time": "2024-07-17T03:00:39.145553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hap3D\n",
    "'''\n",
    "Difference in RBM3 and IQSEC2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162d622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:00:41.132243Z",
     "start_time": "2024-07-17T03:00:39.424265Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datatable as dt\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_color_codes(\"pastel\") # 颜色设定\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "import pybedtools\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import ttest_rel\n",
    "from pybedtools import BedTool\n",
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats import multitest\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fceb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:00:41.141229Z",
     "start_time": "2024-07-17T03:00:41.135600Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams \n",
    "rcParams['pdf.fonttype'] = 42 # True font\n",
    "rcParams['font.size'] =  8  \n",
    "rcParams['grid.linewidth'] =  0.5 \n",
    "rcParams['lines.color'] = 'b' \n",
    "rcParams['lines.linewidth'] = 1 \n",
    "rcParams['lines.markersize'] = 3\n",
    "rcParams['lines.markeredgewidth'] = 0 # set Marker with no edgelines\n",
    "rcParams['axes.linewidth'] = 0.5\n",
    "rcParams['axes.titlesize'] = 12\n",
    "rcParams['axes.labelsize'] = 8\n",
    "rcParams['xtick.labelsize'] = 8\n",
    "rcParams['ytick.labelsize'] = 8\n",
    "rcParams['legend.fontsize'] = 8\n",
    "rcParams['legend.title_fontsize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349015e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:08:56.126014Z",
     "start_time": "2024-07-17T03:00:42.266185Z"
    }
   },
   "outputs": [],
   "source": [
    "### laoding phasing fragments\n",
    "Rawdir=\"/data2/linzhuobin/Hap3D_Figures/figure_processing_data/Fig6\"\n",
    "outdir = \"/data2/linzhuobin/Hap3D_Figures/pdf\"\n",
    "filter_Frag =  5\n",
    "region = [\"chrX\",0, 156040895]\n",
    "fhap_list=f'{Rawdir}/fhap_list/chrX/frag-hap_mapq5.list' ## dip3d filter\n",
    "fhap=pd.read_csv(fhap_list,header=None,sep='\\t',names=['rID','fID','chrom','pos','hp'],\n",
    "                usecols = [0,1,2,3,5])\n",
    "fhap[\"chrom\"] = \"chrX\"\n",
    "\n",
    "### read-level phasing stats\n",
    "read_df = fhap.groupby('rID')['hp'].apply(list).reset_index()\n",
    "read_df['h1'] = read_df.hp.apply(lambda x: x.count(1) if 1 in x else 0)\n",
    "read_df['h2'] = read_df.hp.apply(lambda x: x.count(2) if 2 in x else 0)\n",
    "read_df['un'] = read_df.hp.apply(lambda x: x.count(0) if 0 in x else 0)\n",
    "read_df['hp'] = read_df['h1'] + read_df['h2']\n",
    "read_df['Fc'] = read_df['hp'] + read_df['un']\n",
    "read_df['mod_fc'] = read_df.Fc.apply(lambda x: x if x<=10 else 10)\n",
    "read_df['ratio'] = read_df.apply(lambda x: round(x.hp/x.Fc*100,2),axis=1)\n",
    "##### read haplotype assign\n",
    "read_df[\"HP\"] = -1\n",
    "P1 = read_df.h1 == read_df.hp\n",
    "P2 = read_df.h2 == read_df.hp\n",
    "P3 = read_df.ratio == 0\n",
    "read_df.loc[P1, \"HP\"] = 1\n",
    "read_df.loc[P2, \"HP\"] = 2\n",
    "read_df.loc[P3, \"HP\"] = 0\n",
    "Fragmentcount = read_df.set_index(\"rID\").to_dict()['Fc'] # fragment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8950b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:00.018195Z",
     "start_time": "2024-07-17T03:08:56.128392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter hp reads\n",
    "h1_reads = read_df.loc[read_df.HP==1, \"rID\"].values\n",
    "h2_reads = read_df.loc[read_df.HP==2, \"rID\"].values\n",
    "fhap[\"HP\"] = 0\n",
    "fhap.loc[fhap.rID.isin(h1_reads), \"HP\"] = 1\n",
    "fhap.loc[fhap.rID.isin(h2_reads), \"HP\"] = 2\n",
    "fhap_filter = fhap.loc[fhap.HP!=0, :].copy()\n",
    "## filter fragment\n",
    "freads = read_df.loc[read_df.Fc >= filter_Frag, \"rID\"].unique()\n",
    "fhap_filter = fhap_filter.loc[ fhap_filter.rID.isin(freads), :]\n",
    "freads = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97cf83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.062826Z",
     "start_time": "2024-07-17T03:09:00.020108Z"
    }
   },
   "outputs": [],
   "source": [
    "flanksize = 2500 # using flank size to calclate start and end\n",
    "binsize = 5000\n",
    "fhap_filter[\"start\"] = fhap_filter[\"pos\"] - flanksize\n",
    "fhap_filter[\"end\"] = fhap_filter[\"pos\"] + flanksize\n",
    "fhap_filter[\"bin\"] = fhap_filter[\"pos\"].values // binsize\n",
    "fhap_filter[\"Fc\"] = fhap_filter[\"rID\"].apply(lambda x: Fragmentcount[x] )\n",
    "fhap_filter = fhap_filter.loc[:, [\"chrom\", \"start\", \"end\", \"rID\", \"fID\", \"Fc\", \"bin\", \"HP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d53be6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.068381Z",
     "start_time": "2024-07-17T03:09:04.065669Z"
    }
   },
   "outputs": [],
   "source": [
    "binVDF = fhap_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3771511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.080311Z",
     "start_time": "2024-07-17T03:09:04.069954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter\n",
    "def FilterDF(VDF_DF, region, filter_Frag):\n",
    "    ## region filter\n",
    "    print(\"Befor filter : %d\"%len(VDF_DF))\n",
    "    Pchr = VDF_DF.chrom == region[0]\n",
    "    Pregion = (VDF_DF.start >= region[1]) & (VDF_DF.end <= region[2])\n",
    "    VDF_filter = VDF_DF.loc[ Pchr & Pregion , :]\n",
    "    print(\"After Region Filter: %d\"%len(VDF_filter) )\n",
    "    ## fragment filter\n",
    "    #Fragmentcount = VDF_filter.groupby(by=\"read_name\", as_index=True)[\"chrom\"].count()\n",
    "    Fragmentcount = {}\n",
    "    rN = 0\n",
    "    fIDlist = []\n",
    "    for  n, rowval in VDF_filter.iterrows():\n",
    "        read_name = rowval[\"read_name\"]\n",
    "        if read_name not in Fragmentcount :\n",
    "            #rN = shorten_readname(read_name) # short readID\n",
    "            rN = read_name\n",
    "            fc = 1\n",
    "            fN = 0\n",
    "        else:\n",
    "            rN, fc = Fragmentcount[read_name]\n",
    "            fc += 1\n",
    "        Fragmentcount[read_name] = (rN, fc)\n",
    "        fIDlist.append(fN)\n",
    "        fN += 1\n",
    "    ### fragment ID\n",
    "    Fragment_df = pd.DataFrame(Fragmentcount).T\n",
    "    Fragment_df.columns = [\"rID\", \"count\"]\n",
    "    VDF_filter = VDF_filter.set_index(\"read_name\")\n",
    "    VDF_filter[\"Fc\"] = 0\n",
    "    VDF_filter.loc[:, \"Fc\"] = Fragment_df.loc[VDF_filter.index, \"count\"]\n",
    "    VDF_filter.loc[:, \"rID\"] = Fragment_df.loc[VDF_filter.index, \"rID\"]\n",
    "\n",
    "    VDF_filter[\"fID\"] = fIDlist\n",
    "    VDF_filter = VDF_filter.loc[ VDF_filter.Fc >= filter_Frag, :] \n",
    "    VDF_filter = VDF_filter.reset_index(drop=True)\n",
    "    print(\"After Fragment number Filter: %d reads\"%len( set(VDF_filter.rID.values) ) )\n",
    "    return (VDF_filter)\n",
    "\n",
    "# Bins \n",
    "def BinsDF(df, binsize=1000):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"pos\"] = (df.start.values + df.end.values)/2\n",
    "    df[\"pos\"] = df[\"pos\"].astype(\"int\")\n",
    "    df[\"bin\"] =  ( df[\"pos\"].values/binsize ).astype(\"int\")\n",
    "    #df = df.drop([\"start\", \"end\", \"Fragnum\"], axis=1)\n",
    "    return (df)\n",
    "\n",
    "# Loading\n",
    "def Loading(filename, region, filter_Frag, binsize = 1000):\n",
    "    '''\n",
    "    paf Loading\n",
    "    '''\n",
    "    print(\"Loading %s\"%filename)\n",
    "    usecols = [0,5,7,8]\n",
    "    colnames = ['read_name', 'chrom', 'start', 'end']\n",
    "    VDF_DF = LoadTables(filename, \"\\t\",  usecols, colnames)\n",
    "    VDF_filter = FilterDF(VDF_DF, region, filter_Frag)\n",
    "    del(VDF_DF)\n",
    "    gc.collect()\n",
    "    # Bin calculate\n",
    "    bin_df = BinsDF(VDF_filter, binsize)\n",
    "    bin_df = bin_df.loc[:, [\"chrom\", \"start\", \"end\", \"rID\", \"fID\", \"Fc\", \"bin\"]]\n",
    "    del(VDF_filter)\n",
    "    return(bin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2375cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.091452Z",
     "start_time": "2024-07-17T03:09:04.081817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading promoter bed\n",
    "def LoadingPro(filename, region, binsize):\n",
    "    print(\"Loading %s\"%filename)\n",
    "    bedDF = pd.read_csv(filename, sep=\"\\t\", header=None, \n",
    "                        usecols=[0,1,2,6], names=[\"chrom\",\"start\",\"end\",\"ID\"])\n",
    "    Pchr = bedDF.chrom == region[0]\n",
    "    Pregion = (bedDF.start >= region[1]) & (bedDF.end <= region[2])\n",
    "    bedDF = bedDF.loc[Pchr&Pregion,:]\n",
    "    bedDF = BinsDF(bedDF, binsize)\n",
    "    bedDF = bedDF.loc[:, [\"chrom\", \"start\", \"end\", \"ID\", \"bin\"]]\n",
    "    return(bedDF)\n",
    "\n",
    "def LoadingEnhancerbed(filename, region, binsize=1000, disthred = 5000, flanklen=0):\n",
    "    print(\"Loading %s\"%filename)\n",
    "    input_bed = BedTool(filename)\n",
    "    merged_bed = input_bed.sort().merge( d = disthred) # merge the region within disthred\n",
    "    merged_bed.saveas('/tmp/merged.bed')\n",
    "    bedDF = pd.read_csv( '/tmp/merged.bed', sep=\"\\t\", header=None,  names=[\"chrom\", \"start\", \"end\"], usecols=[0,1,2] )\n",
    "    # enhancer flank : if enhancer length < flanklen, than change the enhancer to the size of flanklen\n",
    "    if flanklen > 0:\n",
    "        Pos = (bedDF.end.values + bedDF.start.values) // 2\n",
    "        starts1, ends1 = Pos - flanklen//2, Pos + flanklen//2\n",
    "        P = (bedDF.end.values - bedDF.start.values) < flanklen\n",
    "        bedDF.loc[P, \"start\"] = starts1[P]\n",
    "        bedDF.loc[P, \"end\"] = ends1[P]\n",
    "    # region filter\n",
    "    Pchr = bedDF.chrom == region[0]\n",
    "    Pregion = (bedDF.start >= region[1]) & (bedDF.end <= region[2])\n",
    "    bedDF = bedDF.loc[Pchr&Pregion,:]\n",
    "    bedDF = BinsDF(bedDF, binsize)\n",
    "    bedDF[\"ID\"] = \"en\"\n",
    "    bedDF[\"ID\"] = bedDF[\"ID\"].str.cat(bedDF.index.astype(\"str\") )\n",
    "    bedDF = bedDF.loc[:, [\"chrom\", \"start\", \"end\", \"ID\", \"bin\"] ]\n",
    "    bedDF = bedDF.loc[:, [\"chrom\", \"start\", \"end\", \"ID\", \"bin\"] ]\n",
    "    return(bedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ada097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.511370Z",
     "start_time": "2024-07-17T03:09:04.093075Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enhancerfile = f\"{Rawdir}/pre_data/GM12878_chrX_pELS.bed\"\n",
    "promoterfile =  f\"{Rawdir}/pre_data/TSS_sorted.txt\"\n",
    "pro_bed =  LoadingPro(promoterfile, region, binsize)\n",
    "pro_bed[\"pos\"] = ( pro_bed.start.values +  pro_bed.end.values ) // 2\n",
    "# binsize 1kb;  merge enhancers within 5kb;  enhancers small than 5kb will resize to 5kb\n",
    "en_bed = LoadingEnhancerbed(enhancerfile, region, 1000, 5000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedf78f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:09:04.522195Z",
     "start_time": "2024-07-17T03:09:04.513939Z"
    }
   },
   "outputs": [],
   "source": [
    "probin_dict = pro_bed.set_index(\"bin\").to_dict()[\"ID\"] # bin and ID dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebd374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:10:53.036935Z",
     "start_time": "2024-07-17T03:09:04.523949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Intersect\n",
    "pbed = BedTool.from_dataframe(pro_bed)\n",
    "ebed = BedTool.from_dataframe(en_bed)\n",
    "fbed = BedTool.from_dataframe(binVDF)\n",
    "\n",
    "## fbed <-> pbed\n",
    "intersect = fbed.intersect(pbed, wa=True, wb=True, loj=True)\n",
    "intersect2 = intersect.intersect(ebed, wa=True, wb=True, loj=True)\n",
    "\n",
    "colnames = [\"chrom\", \"start\", \"end\", \"rID\", \"fID\",\"Fc\", \"bin\",\"HP\",\n",
    "            \"Pchrom\", \"Pstart\", \"Pend\", \"PID\", \"Pbin\", \"Ppos\",\n",
    "           \"Echrom\", \"Estart\", \"Eend\", \"EID\", \"Ebin\"]\n",
    "int_df = intersect2.to_dataframe(names=colnames)\n",
    "int_df = int_df.drop([\"Pchrom\", \"Pstart\", \"Pend\", \"Pbin\", \"Ppos\",\"Echrom\", \"Estart\", \"Eend\", \"Ebin\"], axis=1)\n",
    "# 清理临时文件\n",
    "pybedtools.cleanup() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e76d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:25:18.994218Z",
     "start_time": "2024-07-17T03:10:53.041059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Promoter-Enhancer model summary\n",
    "## 全chromosome 范围 \n",
    "Pro_dict = pro_bed.set_index('ID').to_dict()[\"pos\"]\n",
    "Promoters = int_df.PID.unique()\n",
    "rIDs = int_df.loc[int_df.PID !=\".\", \"rID\"].unique()\n",
    "df = int_df.loc[int_df.rID.isin(rIDs), :].reset_index()\n",
    "## Enhancer types\n",
    "Enhancer_list = []\n",
    "for rID, gdf in df.groupby(\"rID\"):\n",
    "    gdf = gdf.reset_index()\n",
    "    HP = gdf.HP.values[0]\n",
    "    for PID in gdf.PID.unique():\n",
    "        if PID != \".\" :\n",
    "            P = gdf.PID == PID\n",
    "            ## 非promoter fragment 去重\n",
    "            pgdf = gdf.loc[(~P), :].drop_duplicates(subset=['rID', 'fID'], keep='first').reset_index(drop=True).copy()\n",
    "            EIDs = pgdf.loc[pgdf.EID!=\".\", \"EID\"].unique() # 非promoter fragment中包含Enhancer IDs\n",
    "            Ecount = len(EIDs)\n",
    "            EIDs = \",\".join( sorted( list(EIDs) ) )\n",
    "            if Ecount <= 0:\n",
    "                Etype = \"NE\"\n",
    "            elif Ecount == 1:\n",
    "                Etype = \"SE\"\n",
    "            else:\n",
    "                Etype = \"ME\"\n",
    "            item = (rID, HP, PID, EIDs, Ecount,  Etype)\n",
    "            Enhancer_list.append( item )\n",
    "            \n",
    "Ereads_df = pd.DataFrame( Enhancer_list, columns = [\"rID\", \"HP\", \"PID\", \"EIDs\", \"Ecount\", \"EType\"])\n",
    "## Ehancer contact model summary\n",
    "Esummary_df = Ereads_df.groupby([\"PID\", \"HP\", \"EType\"])[\"rID\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141d18c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:25:19.041056Z",
     "start_time": "2024-07-17T03:25:18.996167Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_df = pd.pivot_table(Esummary_df, values='rID', \n",
    "                          index='PID', columns=['HP', \"EType\"], aggfunc='sum', fill_value=0 )\n",
    "pivot_df[\"1_SE_ratio\"] =  pivot_df.loc[:, (1, \"SE\")].values / pivot_df.loc[:, [(1, \"ME\"), (1, \"SE\"), (1, \"NE\")]].sum(axis=1)\n",
    "pivot_df[\"1_ME_ratio\"] =  pivot_df.loc[:, (1, \"ME\")].values / pivot_df.loc[:, [(1, \"ME\"), (1, \"SE\"), (1, \"NE\")]].sum(axis=1)\n",
    "pivot_df[\"2_SE_ratio\"] =  pivot_df.loc[:, (2, \"SE\")].values / pivot_df.loc[:, [(2, \"ME\"), (2, \"SE\"), (2, \"NE\")]].sum(axis=1)\n",
    "pivot_df[\"2_ME_ratio\"] =  pivot_df.loc[:, (2, \"ME\")].values / pivot_df.loc[:, [(2, \"ME\"), (2, \"SE\"), (2, \"NE\")]].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c9de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:25:19.046281Z",
     "start_time": "2024-07-17T03:25:19.042574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subsampling\n",
    "import random\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "def Subsampling(readlist, sample_size=100):\n",
    "    '''\n",
    "    subsampling the list by sample_size\n",
    "    '''\n",
    "    readlist = list(readlist)\n",
    "    sublist =  random.sample(readlist, sample_size)\n",
    "    return(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baaab86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T03:25:20.822878Z",
     "start_time": "2024-07-17T03:25:19.047857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enhancer interaction Plot\n",
    "res_region = 1000000\n",
    "flank =  0.05*10**6\n",
    "ProID = \"ENSG00000102317.17\"\n",
    "Eread_dict = Ereads_df.set_index('rID').to_dict()[\"EType\"]\n",
    "rIDs = int_df.loc[int_df.PID ==ProID, \"rID\"].unique()\n",
    "plot_df = int_df.loc[int_df.rID.isin(rIDs), :].copy()\n",
    "plot_df[\"pos\"] = ( plot_df.start + plot_df.end)//2\n",
    "plot_df[\"EType\"] = plot_df.rID.apply( lambda x: Eread_dict[x] )\n",
    "ETypedict = {\"NE\":0, \"SE\":1, \"ME\":2}\n",
    "plot_df[\"ETypeNum\"] = plot_df[\"EType\"].apply(lambda x: ETypedict[x])\n",
    "## Hp readscount\n",
    "h1reads, h2reads = plot_df.loc[plot_df.HP==1, \"rID\"].unique(), plot_df.loc[plot_df.HP==2, \"rID\"].unique() \n",
    "HPreadcount = {1:len(h1reads),\n",
    "               2:len(h2reads)}\n",
    "## enhancer fragment out of regions\n",
    "P1 =  (plot_df[\"pos\"]  >  Pro_dict[ProID] + res_region*0.5) * (plot_df[\"EID\"]!= \".\")\n",
    "plot_df.loc[P1, \"pos\"] = Pro_dict[ProID] + res_region*0.5\n",
    "P2 =  (plot_df[\"pos\"]  < Pro_dict[ProID] - res_region*0.5) * (plot_df[\"EID\"]!= \".\")\n",
    "plot_df.loc[P2, \"pos\"] = Pro_dict[ProID] - res_region*0.5\n",
    "## filter out other fragments not in regions\n",
    "Pres = ( plot_df[\"pos\"] - Pro_dict[ProID] ).abs() <=  res_region //2 # regtrition region fragments\n",
    "plot_df = plot_df.loc[Pres, :]\n",
    "\n",
    "## remove Unknow Etype\n",
    "Unreads = plot_df.loc[plot_df.EType!=\"Un\", \"rID\"].unique()\n",
    "plot_df = plot_df.loc[ plot_df.rID.isin(Unreads), :].reset_index()\n",
    "\n",
    "# # Subsampling\n",
    "select_reads = Subsampling(h1reads, 100)\n",
    "select_reads.extend( Subsampling(h2reads, 100) )\n",
    "plot_df = plot_df.loc[ plot_df.rID.isin(select_reads), :].reset_index()\n",
    "\n",
    "## filter region  enhancers\n",
    "en_bed[\"pos\"] = ( en_bed.start + en_bed.end ) // 2\n",
    "P = ( en_bed[\"pos\"] - Pro_dict[ProID] ).abs() <=  res_region //2 \n",
    "en_fbed = en_bed.loc[P,:].reset_index() # regtrition region enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f39ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T09:09:59.117326Z",
     "start_time": "2023-09-12T09:09:56.431757Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Multiway Enhancer model\n",
    "FigRow, FigCol = 3, 1\n",
    "fig, Axs = plt.subplots(FigRow, FigCol, figsize=(4,  3),\n",
    "                        gridspec_kw={'height_ratios': [5, 47.5, 47.5]}, \n",
    "                        sharex=True)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.05)\n",
    "print(Pro_dict[ProID] - res_region*0.5, Pro_dict[ProID] + res_region*0.5)\n",
    "# Promoter and Enhancer \n",
    "for index, rowdf in en_fbed.iterrows():\n",
    "    start, end = rowdf[\"start\"], rowdf[\"end\"]\n",
    "    ID = rowdf[\"ID\"]\n",
    "    xs, ys = [start, end], [1, 1]\n",
    "    Axs[0].plot(xs, ys, c=\"orange\", linewidth=1)\n",
    "Axs[0].set_yticks([])\n",
    "Axs[0].set_ylabel(\"Enhancer\", fontsize=8)\n",
    "\n",
    "for HP, gdf in plot_df.groupby(\"HP\"):\n",
    "    gdf = gdf.sort_values(by=[\"ETypeNum\", \"start\"]).reset_index(drop=True)\n",
    "    HPreads = gdf.rID.unique()\n",
    "    HrCount = len(HPreads) \n",
    "    yN = 0\n",
    "    for rID in HPreads:\n",
    "        P = gdf.rID == rID\n",
    "        aread_df = gdf.loc[P, :]\n",
    "        rstart, rend = aread_df.start.min(), aread_df.end.max()\n",
    "        if rstart <= Pro_dict[ProID] - res_region*0.5:\n",
    "            rstart = Pro_dict[ProID] - res_region*0.5\n",
    "        if rend >= Pro_dict[ProID] + res_region*0.5:\n",
    "            rend = Pro_dict[ProID] + res_region*0.5\n",
    "        xs, ys = [rstart, rend], [yN, yN]\n",
    "        if aread_df.EType.values[0] == \"SE\":\n",
    "            sc = \"cyan\"\n",
    "        elif  aread_df.EType.values[0] == \"ME\":\n",
    "            sc = \"purple\"\n",
    "        else:\n",
    "            sc = \"grey\"\n",
    "        Axs[HP].plot(xs, ys, c=sc, linewidth=0.2, alpha = 1)\n",
    "        \n",
    "        for index, rowdf in aread_df.iterrows():\n",
    "            if rowdf[\"PID\"] == ProID :\n",
    "                if HP == 1:\n",
    "                    sc = \"red\"\n",
    "                else:\n",
    "                    sc = \"blue\"\n",
    "                if rowdf[\"EID\"] != \".\":\n",
    "                    overlap_en = rowdf[\"EID\"]\n",
    "            #elif \"en\" in rowdf[\"EID\"] and rowdf[\"EID\"] != overlap_en and aread_df.EType.values[0] != \"NE\":\n",
    "            elif \"en\" in rowdf[\"EID\"] and aread_df.EType.values[0] != \"NE\":\n",
    "                sc = \"orange\"\n",
    "            else:\n",
    "                sc = \"grey\"\n",
    "            Axs[HP].plot(rowdf[\"pos\"], yN, marker=\"s\", c=sc, markersize=1)\n",
    "        yN += 1\n",
    "\n",
    "    Axs[HP].set_xticks([])\n",
    "    Axs[HP].set_yticks([])\n",
    "    # Multiway Enhancer ratio\n",
    "    MEratio = pivot_df.loc[ProID, f\"{HP}_ME_ratio\"]\n",
    "    SEratio = pivot_df.loc[ProID, f\"{HP}_SE_ratio\"]\n",
    "    Axs[HP].set_ylabel( \"HP %d\\nN=%d\\nME=%.3f\\nSE=%.3f\\nNE=%.3f\"%(HP, HPreadcount[HP], MEratio, SEratio, 1-MEratio-SEratio), fontsize=8 )\n",
    "\n",
    "xS, xE = Pro_dict[ProID] - res_region //2, Pro_dict[ProID]+ res_region //2 \n",
    "plt.xlim([xS-1.5*flank, xE+1.5*flank])\n",
    "# xticks\n",
    "Xtick = list( np.linspace(xS, xE, 5 ,endpoint=True) )\n",
    "Xtick_label = [ \"%.3f\"%(i/10**6) for i in Xtick ]\n",
    "plt.xticks( Xtick, Xtick_label)\n",
    "plt.xlabel(\"%s Mb\"%(region[0] ) )\n",
    "Axs[0].set_title(ProID, fontsize=8)\n",
    "#plt.show()\n",
    "plt.savefig(f\"{outdir}/ME_interaction_line_plot_{ProID}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee07093d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T05:03:49.539720Z",
     "start_time": "2024-07-17T05:03:47.652433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enhancer interaction Plot \n",
    "## UBA1 ENSG00000130985.16 VGLL1  ENSG00000102243.12\n",
    "# CTPS2 ENSG00000047230.14\n",
    "res_region = 1000000\n",
    "flank =  0.05*res_region\n",
    "ProID = \"ENSG00000124313.14\"\n",
    "Eread_dict = Ereads_df.set_index('rID').to_dict()[\"EType\"]\n",
    "rIDs = int_df.loc[int_df.PID ==ProID, \"rID\"].unique()\n",
    "plot_df = int_df.loc[int_df.rID.isin(rIDs), :].copy()\n",
    "plot_df[\"pos\"] = ( plot_df.start + plot_df.end)//2\n",
    "plot_df[\"EType\"] = plot_df.rID.apply( lambda x: Eread_dict[x] )\n",
    "ETypedict = {\"NE\":0, \"SE\":1, \"ME\":2}\n",
    "plot_df[\"ETypeNum\"] = plot_df[\"EType\"].apply(lambda x: ETypedict[x])\n",
    "## Hp readscount\n",
    "h1reads, h2reads = plot_df.loc[plot_df.HP==1, \"rID\"].unique(), plot_df.loc[plot_df.HP==2, \"rID\"].unique() \n",
    "HPreadcount = {1:len(h1reads),\n",
    "               2:len(h2reads)}\n",
    "## enhancer fragment out of regions\n",
    "P1 =  (plot_df[\"pos\"]  >  Pro_dict[ProID] + res_region*0.5) * (plot_df[\"EID\"]!= \".\")\n",
    "plot_df.loc[P1, \"pos\"] = Pro_dict[ProID] + res_region*0.5\n",
    "P2 =  (plot_df[\"pos\"]  < Pro_dict[ProID] - res_region*0.5) * (plot_df[\"EID\"]!= \".\")\n",
    "plot_df.loc[P2, \"pos\"] = Pro_dict[ProID] - res_region*0.5\n",
    "## filter out other fragments not in regions\n",
    "Pres = ( plot_df[\"pos\"] - Pro_dict[ProID] ).abs() <=  res_region //2 # regtrition region fragments\n",
    "plot_df = plot_df.loc[Pres, :]\n",
    "\n",
    "## remove Unknow Etype\n",
    "Unreads = plot_df.loc[plot_df.EType!=\"Un\", \"rID\"].unique()\n",
    "plot_df = plot_df.loc[ plot_df.rID.isin(Unreads), :].reset_index()\n",
    "\n",
    "# # Subsampling\n",
    "select_reads = Subsampling(h1reads, 100)\n",
    "select_reads.extend( Subsampling(h2reads, 100) )\n",
    "plot_df = plot_df.loc[ plot_df.rID.isin(select_reads), :].reset_index()\n",
    "\n",
    "## filter region  enhancers\n",
    "en_bed[\"pos\"] = ( en_bed.start + en_bed.end ) // 2\n",
    "P = ( en_bed[\"pos\"] - Pro_dict[ProID] ).abs() <=  res_region //2 \n",
    "en_fbed = en_bed.loc[P,:].reset_index() # regtrition region enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752cbd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T05:03:52.421879Z",
     "start_time": "2024-07-17T05:03:49.542030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Multiway Enhancer model\n",
    "FigRow, FigCol = 3, 1\n",
    "fig, Axs = plt.subplots(FigRow, FigCol, figsize=(4,  3),\n",
    "                        gridspec_kw={'height_ratios': [5, 47.5, 47.5]}, \n",
    "                        sharex=True)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.05)\n",
    "print(Pro_dict[ProID] - res_region*0.5, Pro_dict[ProID] + res_region*0.5)\n",
    "# Promoter and Enhancer \n",
    "for index, rowdf in en_fbed.iterrows():\n",
    "    start, end = rowdf[\"start\"], rowdf[\"end\"]\n",
    "    ID = rowdf[\"ID\"]\n",
    "    xs, ys = [start, end], [1, 1]\n",
    "    Axs[0].plot(xs, ys, c=\"orange\", linewidth=1)\n",
    "Axs[0].set_yticks([])\n",
    "Axs[0].set_ylabel(\"Enhancer\", fontsize=8)\n",
    "\n",
    "for HP, gdf in plot_df.groupby(\"HP\"):\n",
    "    gdf = gdf.sort_values(by=[\"ETypeNum\", \"start\"]).reset_index(drop=True)\n",
    "    HPreads = gdf.rID.unique()\n",
    "    HrCount = len(HPreads) \n",
    "    yN = 0\n",
    "    for rID in HPreads:\n",
    "        P = gdf.rID == rID\n",
    "        aread_df = gdf.loc[P, :]\n",
    "        rstart, rend = aread_df.start.min(), aread_df.end.max()\n",
    "        if rstart <= Pro_dict[ProID] - res_region*0.5:\n",
    "            rstart = Pro_dict[ProID] - res_region*0.5\n",
    "        if rend >= Pro_dict[ProID] + res_region*0.5:\n",
    "            rend = Pro_dict[ProID] + res_region*0.5\n",
    "        xs, ys = [rstart, rend], [yN, yN]\n",
    "        if aread_df.EType.values[0] == \"SE\":\n",
    "            sc = \"cyan\"\n",
    "        elif  aread_df.EType.values[0] == \"ME\":\n",
    "            sc = \"purple\"\n",
    "        else:\n",
    "            sc = \"grey\"\n",
    "        Axs[HP].plot(xs, ys, c=sc, linewidth=0.2, alpha = 1)\n",
    "        \n",
    "        for index, rowdf in aread_df.iterrows():\n",
    "            if rowdf[\"PID\"] == ProID :\n",
    "                if HP == 1:\n",
    "                    sc = \"red\"\n",
    "                else:\n",
    "                    sc = \"blue\"\n",
    "                if rowdf[\"EID\"] != \".\":\n",
    "                    overlap_en = rowdf[\"EID\"]\n",
    "            elif \"en\" in rowdf[\"EID\"] and aread_df.EType.values[0] != \"NE\":\n",
    "                sc = \"orange\"\n",
    "            else:\n",
    "                sc = \"grey\"\n",
    "            Axs[HP].plot(rowdf[\"pos\"], yN, marker=\"s\", c=sc, markersize=1)\n",
    "        yN += 1\n",
    "\n",
    "    Axs[HP].set_xticks([])\n",
    "    Axs[HP].set_yticks([])\n",
    "    # Multiway Enhancer ratio\n",
    "    MEratio = pivot_df.loc[ProID, f\"{HP}_ME_ratio\"]\n",
    "    SEratio = pivot_df.loc[ProID, f\"{HP}_SE_ratio\"]\n",
    "    Axs[HP].set_ylabel( \"HP %d\\nN=%d\\nME=%.3f\\nSE=%.3f\\nNE=%.3f\"%(HP, HPreadcount[HP], MEratio, SEratio, 1-MEratio-SEratio), fontsize=8 )\n",
    "\n",
    "xS, xE = Pro_dict[ProID] - res_region //2, Pro_dict[ProID]+ res_region //2 \n",
    "plt.xlim([xS-1.5*flank, xE+1.5*flank])\n",
    "# xticks\n",
    "Xtick = list( np.linspace(xS, xE, 5 ,endpoint=True) )\n",
    "Xtick_label = [ \"%.3f\"%(i/10**6) for i in Xtick ]\n",
    "plt.xticks( Xtick, Xtick_label)\n",
    "plt.xlabel(\"%s Mb\"%(region[0] ) )\n",
    "Axs[0].set_title(ProID, fontsize=8)\n",
    "#plt.show()\n",
    "plt.savefig(f\"{outdir}/ME_interaction_line_plot_{ProID}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3610d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
